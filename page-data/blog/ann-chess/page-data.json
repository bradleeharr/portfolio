{"componentChunkName":"component---src-pages-blog-markdown-remark-frontmatter-slug-jsx","path":"/blog/ann-chess/","result":{"data":{"markdownRemark":{"html":"<p><strong>Creating a Chess AI based on my Lichess game database.</strong> Project for ECE 5973 Artificial Neural Networks [and further work in progress]</p>\n<h2>1 | Introduction</h2>\n<p>The problem of chess has been one of the earliest tasks in machine learning. Researchers such as Alan Turing and Claude Shannon had both published papers on computers chess algorithms in the early days of computing.</p>\n<p>In modern times, chess is still unsolved. In fact, it is very likely unsolvable.\r\nBut computers are much better at solving the problem than humans. An interesting thing about modern chess computers is that they use machine learning models based on human intuition to perform astronomically better than humans.</p>\n<h2>2 | Problem</h2>\n<p>Computer chess engines, powered by neural networks and reinforcement learning, excel in game solutions. However, many suggest moves distinct from human choices due to their computational accuracy.\r\nThis disparity can hinder human learning from such engines. An exemplar of human-like chess AI is <a href=\"https://maiachess.com/\">Maia Chess</a>. My project's objective is to use deep learning to mimic personal chess styles, emphasizing capturing human decision-making in rapid games.</p>\n<h2>3 | Data</h2>\n<p>I focused on personal game datasets to ensure unique results. The dataset (~2,000 games) is optimized for an AMD Ryzen CPU without GPU acceleration.\r\nIt comprises 1,633 Bullet, 165 Blitz, and 244 Rapid games. Emphasizing Bullet games captures impulsive decisions, providing a comprehensive play style view. All games were split into train, validation, and test sets (75-15-15).</p>\n<h2>4 | Methods</h2>\n<p><strong>4.0 Board Features</strong>:</p>\n<p>8x8x12 map representation, where each 8x8 channel denotes a piece (12 total). A '1' indicates the presence of a piece and '0' its absence.</p>\n<p><strong>4.1 Move Features</strong>:</p>\n<p>Moves were translated from the <a href=\"https://www.chessprogramming.org/UCI\">Universal Chess Interface</a> to a numerical system, leading to 4096 potential classes.</p>\n<p><strong>4.2 Random Valid Move Model</strong>:</p>\n<p>A baseline model, achieving 3.1-3.6% accuracy through random move selection.</p>\n<h2>5 | Base Convolutional Model:</h2>\n<p><img src=\"https://github.com/bradleeharr/BradleeAI/assets/56418392/ec95dcc9-ee64-4d30-9167-0b18f78e52ca\" alt=\"image\"></p>\n<p>The base convolutional model uses a convolutional neural network with a variable number of layers.</p>\n<ul>\n<li>Utilizes a convolutional neural network with variable layer counts.</li>\n<li>Each layer maintains consistent input-output channels with a 3x3 kernel and padding.</li>\n<li>Output is flattened and connected to two dense layers, culminating in a 4096-long channel.</li>\n<li>Model trained by comparing cross-entropy loss between output and move classifications.</li>\n</ul>\n<p>The best model had losses of 0.9274 (training), 4.616 (validation), and 4.696 (test). This led to a move prediction accuracy of 14.24%.</p>\n<h2>6 | Residual Model</h2>\n<p><img src=\"https://github.com/bradleeharr/BradleeAI/assets/56418392/81102fdc-193e-4ccc-a161-fffa3956efb1\" alt=\"image\"></p>\n<p>After hyperparameter adjustments, this model had a top move prediction accuracy of 10.21%. Though inferior to the convolutional model, it outperforms the random baseline. Its intricate structure, combined with a smaller dataset, poses training challenges.</p>\n<h2>7 | Summary</h2>\n<p>In summary, we can see that some features are being captured by training convolutional neural network models against this small and limited dataset and the move prediction accuracy is improving, which shows successful progress. However, there is still much to be improved upon.</p>","frontmatter":{"date":"December 15, 2022","slug":"ann-chess","title":"Chess Neural Networks"}},"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"slug":null,"title":""}}},{"node":{"frontmatter":{"slug":"test-post","title":"Test"}}},{"node":{"frontmatter":{"slug":"spectrogram-iq","title":"How to Look at a Spectrogram with IQEngine"}}},{"node":{"frontmatter":{"slug":"l-m-hdpc","title":"On Low, Medium, and High Density Parity Check Codes"}}},{"node":{"frontmatter":{"slug":"my-first-blog-post","title":"Gatsby and Katex: Using Markdown to create posts with LaTeX format supported"}}},{"node":{"frontmatter":{"slug":"a-dance-rhythm-game","title":"A Dance Rhythm Game using an LPC1769 Microcontroller and DE10-Lite FPGA"}}},{"node":{"frontmatter":{"slug":"antennas-from-military-handbook","title":"An Introduction to Antennas from the US Military Field Antenna Handbook"}}},{"node":{"frontmatter":{"slug":"fpga-resources","title":"FPGA Resources - Verilog/VHDL "}}},{"node":{"frontmatter":{"slug":"dropping-needles-approximating-pi","title":"A Dance Rhythm Game using an LPC1769 Microcontroller and DE10-Lite FPGA"}}},{"node":{"frontmatter":{"slug":"cross-site-scripting","title":"Introduction to Cross-Site-Scripting"}}},{"node":{"frontmatter":{"slug":"ann-chess","title":"Chess Neural Networks"}}},{"node":{"frontmatter":{"slug":"an-amplitude-modulator","title":"A Design and Implementation of a 100 kHz Amplitude Modulator Circuit Using Basic Components"}}}]}},"pageContext":{"id":"7b1d11a5-bd11-58e9-9134-511a2a3dfe9b","frontmatter__slug":"ann-chess","__params":{"frontmatter__slug":"ann-chess"}}},"staticQueryHashes":[],"slicesMap":{}}